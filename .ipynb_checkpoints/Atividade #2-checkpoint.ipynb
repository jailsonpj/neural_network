{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste 2 - 11/09/2018\n",
    "\n",
    "## Disponibilização: 10/09/2018 - 11h\n",
    "## Encerramento: 11/09/2018 - 20h\n",
    "\n",
    "O objetivo deste segundo projeto prático da disciplina Redes Neurais Artificias é praticar os conceitos de Machine Learning vistos até o momento, em especial aqueles relativos ao processo de Aprendizagem de Máquina.\n",
    "\n",
    "Vamos trabalhar com o dataset **Breast Cancer Wisconsin (Diagnostic) Data Set**, vide: <a href=\"https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)\">Repositório UCI</a>\n",
    "\n",
    "Esta tarefa é dividida em to-dos, isto é, pequenas atividades que devem ser cumpridas para que o objetivo geral seja alcançado. A cada to-do está associada uma célula do Jupyter Notebook, que deve ser preenchida com código Python atendendo ao que se pede.\n",
    "\n",
    "\n",
    "Edite aqui o nome da equipe:\n",
    "\n",
    "- Jailson Pereira Januário (1315170056)\n",
    "- Jackson Kelvin Souza (1515310012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize seus imports nesta célula\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To-Do 1\n",
    "\n",
    "1. Você deve importar o dataset a partir do sci-kit learn.\n",
    "Consulte o link: [Link da documentação do sci-kit learn](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer)\n",
    "   * Este dataset está organizado sob a forma de um dicionário, em que os dados preditores encontram-se na chave 'data', composta de diversas matrizes. Cada matriz está associada a um nome 'feature_names'. \n",
    "2. Crie um novo dicionário que mapeia cada 'feature_name' para uma matriz correspondente.\n",
    "    * Antes de fazer esta associação, transponha a matriz localizada na chave 'data' para obter a dimensão correta.\n",
    "3. Transforme o dataset em um objetivo tipo DataFrame do pandas\n",
    "4. Adicione o atributo-alvo ao dataset existente.\n",
    "    * Importante: O atributo-alvo está na chave 'target' do dicionário, com nome 'target_names'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "data = load_breast_cancer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "data_novo = {}\n",
    "data_trans = np.transpose(data.data)\n",
    "\n",
    "for i in range(len(data.feature_names)):\n",
    "    data_novo[data.feature_names[i]] = data_trans[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "df = pd.DataFrame(data_novo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "target = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To-Do 2\n",
    "\n",
    "Utilizando `pandas.DataFrame` para manipular o dataset, faça o que se pede:\n",
    "1. Informe a quantidade de exemplos existentes no dataset\n",
    "2. Enumere os atributos existentes no dataset\n",
    "3. Identifique o atributo-alvo e imprima-o\n",
    "4. O dataset é balanceado?\n",
    "5. Remova todos os atributos que contenham a palavra `error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      "mean radius                569 non-null float64\n",
      "mean texture               569 non-null float64\n",
      "mean perimeter             569 non-null float64\n",
      "mean area                  569 non-null float64\n",
      "mean smoothness            569 non-null float64\n",
      "mean compactness           569 non-null float64\n",
      "mean concavity             569 non-null float64\n",
      "mean concave points        569 non-null float64\n",
      "mean symmetry              569 non-null float64\n",
      "mean fractal dimension     569 non-null float64\n",
      "radius error               569 non-null float64\n",
      "texture error              569 non-null float64\n",
      "perimeter error            569 non-null float64\n",
      "area error                 569 non-null float64\n",
      "smoothness error           569 non-null float64\n",
      "compactness error          569 non-null float64\n",
      "concavity error            569 non-null float64\n",
      "concave points error       569 non-null float64\n",
      "symmetry error             569 non-null float64\n",
      "fractal dimension error    569 non-null float64\n",
      "worst radius               569 non-null float64\n",
      "worst texture              569 non-null float64\n",
      "worst perimeter            569 non-null float64\n",
      "worst area                 569 non-null float64\n",
      "worst smoothness           569 non-null float64\n",
      "worst compactness          569 non-null float64\n",
      "worst concavity            569 non-null float64\n",
      "worst concave points       569 non-null float64\n",
      "worst symmetry             569 non-null float64\n",
      "worst fractal dimension    569 non-null float64\n",
      "target                     569 non-null int64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 137.9 KB\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3\n",
    "df['target'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valores para target \"1\" 357\n",
      "valores para target \"0\" 212\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "x = df[df['target'] == 1]['target'].count()\n",
    "y = df[df['target'] == 0]['target'].count()\n",
    "\n",
    "print('valores para target \"1\"',x)\n",
    "print('valores para target \"0\"',y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados do dataset estão desbalanceado sendo os de valor 1 com 357 amostras e os de valor 0 com 212 amostras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "\n",
    "aux = re.compile('error') \n",
    "lista = df.columns\n",
    "\n",
    "for i in range(len(lista)):\n",
    "    if aux.search(lista[i]) == None:\n",
    "        continue\n",
    "    df.drop(lista[i],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
       "       'worst smoothness', 'worst compactness', 'worst concavity',\n",
       "       'worst concave points', 'worst symmetry', 'worst fractal dimension',\n",
       "       'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To-Do 3\n",
    "\n",
    "Faça uma partição randomizada do tipo 70/30 para conjunto de treinamento e de testes.\n",
    "Em ambos os conjuntos, separe o atributo-alvo.\n",
    "\n",
    "Para facilitar, siga a nomenclatura sugerida:\n",
    "* X_train: atributos preditores para o conjunto de treinamento\n",
    "* X_test: atributos preditores para o conjunto de testes\n",
    "* Y_train: atributo-alvo para os exemplos do conjunto de treinamento\n",
    "* Y_test: atributo-alvo para os exemplos do conjunto de testes\n",
    "\n",
    "Sugestão: [consultar a documentação do sci-kit learn](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()\n",
    "y = df['target']\n",
    "X = df.drop('target',axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To-Do 4\n",
    "\n",
    "Vamos usar os dados X_train e Y_train para treinar dois modelos diferentes de Aprendizagem de Máquina.\n",
    "1. Modelo 1: Vizinhos mais próximos, com k = 5\n",
    "2. Modelo 2: Centróides mais próximos, de acordo com a distância Euclidiana\n",
    "\n",
    "Basta completar o código a seguir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestCentroid(metric='euclidean', shrink_threshold=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "\n",
    "# 5 - vizinhos mais próximos\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "# Kernel Density\n",
    "nc = NearestCentroid()\n",
    "nc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To-Do 5\n",
    "\n",
    "Utilizar o conjunto de testes para prever o conjunto de testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsaokNN = knn.predict(X_test)\n",
    "previsaonc = nc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To-Do 6\n",
    "\n",
    "Analisando as diferenças e igualdades entre os vetores previsaokNN, previsaonc e Y_test, construa as matrizes de confusão dos respectivos modelos de Machine Learning. \n",
    "\n",
    "Consulte: [Documentação do sklearn para Matrizes de Confusão](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 58,   5],\n",
       "       [  2, 106]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#previsão KNN\n",
    "confusion_matrix(y_test,previsaokNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 49,  14],\n",
       "       [  0, 108]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#previsao nc\n",
    "confusion_matrix(y_test,previsaonc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To-Do 7\n",
    "\n",
    "Para cada um dos modelos, apresente:\n",
    "\n",
    "1. Acurácia\n",
    "2. Precisão\n",
    "3. Revocação\n",
    "4. F-Score (Leve em consideração se o dataset é balanceado ou não)\n",
    "\n",
    "Consulte: [Documentação do sklearn para Métricas de Desempenho](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc KNN:  0.9590643274853801\n",
      "acc nc:  0.9181286549707602\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "print(\"acc KNN: \",accuracy_score(y_test,previsaokNN))\n",
    "print(\"acc nc: \",accuracy_score(y_test,previsaonc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precisao KNN:  0.9590643274853801\n",
      "precisao nc:  0.9181286549707602\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "print(\"precisao KNN: \",precision_score(y_test,previsaokNN,average='micro'))\n",
    "print(\"precisao nc: \",precision_score(y_test,previsaonc,average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall KNN:  0.9590643274853801\n",
      "recall nc:  0.9181286549707602\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "print(\"recall KNN: \",recall_score(y_test, previsaokNN,average='micro'))\n",
    "print(\"recall nc: \",recall_score(y_test, previsaonc,average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Score KNN:  0.9590643274853801\n",
      "F-Score nc:  0.9181286549707602\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "print(\"F-Score KNN: \",f1_score(y_test, previsaokNN,average='micro'))\n",
    "print(\"F-Score nc: \",f1_score(y_test, previsaonc,average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To-Do 8\n",
    "\n",
    "Utilizando argumentos textuais, justifique qual dos modelos apresentados é melhor para o problema em questão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corforme a métrica de recall do KNN dando cerca de 0.95% , ela teve um desempenho melhor que a da Centróide que teve um desempenho de 0.91%. Levando em consideração que a recall diz positivo quando ele não foi que no caso em questão é melhor tratar um negativo como positivo do que um positivo como negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
